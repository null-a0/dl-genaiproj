{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":115439,"databundleVersionId":13800781,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DL-GENAi PROJECT — Scratch BiLSTM\n# Name  : Abhishek Saha\n# Roll  : 23f1001572\n# Model : Scratch BiLSTM ","metadata":{}},{"cell_type":"markdown","source":"## IMPORTS AND SETUP","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport math\nimport time\nimport json\nimport re\nimport html\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport wandb\n!wandb login 20d9b18a55f275c39d05bf53e51e8b328aeffff5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:06.199304Z","iopub.execute_input":"2025-12-01T21:21:06.200116Z","iopub.status.idle":"2025-12-01T21:21:07.639020Z","shell.execute_reply.started":"2025-12-01T21:21:06.200087Z","shell.execute_reply":"2025-12-01T21:21:07.638289Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## CONFIGURATION","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # dataset paths \n    TRAIN_PATH = \"/kaggle/input/2025-sep-dl-gen-ai-project/train.csv\"\n    TEST_PATH  = \"/kaggle/input/2025-sep-dl-gen-ai-project/test.csv\"\n    SAMPLE_SUB = \"/kaggle/input/2025-sep-dl-gen-ai-project/sample_submission.csv\"\n\n    # model / train hyperparams\n    seed = 42\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    max_len = 100\n    min_freq = 2\n    embedding_dim = 128\n    hidden_dim = 384            \n    num_layers = 2              \n    dropout = 0.3\n    num_heads = 4\n    batch_size = 64\n    lr = 3e-4\n    epochs = 15\n    weight_decay = 1e-6\n    clip_grad = 1.0\n    scheduler = \"cosine\"        \n    warmup_steps = 100\n    save_path = \"scratch_bilstm_final.pth\"\n    project = \"23f1001572-t32025\"\n    run_name = \"scratch-bilstm-v2\"\n\nCFG = CFG()\nTARGET_COLS = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:07.640465Z","iopub.execute_input":"2025-12-01T21:21:07.640719Z","iopub.status.idle":"2025-12-01T21:21:07.646757Z","shell.execute_reply.started":"2025-12-01T21:21:07.640696Z","shell.execute_reply":"2025-12-01T21:21:07.646047Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def set_seed(s=CFG.seed):\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(s)\n\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:07.782638Z","iopub.execute_input":"2025-12-01T21:21:07.783285Z","iopub.status.idle":"2025-12-01T21:21:07.788957Z","shell.execute_reply.started":"2025-12-01T21:21:07.783259Z","shell.execute_reply":"2025-12-01T21:21:07.788398Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(CFG.TRAIN_PATH)\ntest  = pd.read_csv(CFG.TEST_PATH)\n\nTARGET_COLS = [\"anger\",\"fear\",\"joy\",\"sadness\",\"surprise\"]\nprint(\"Train shape:\", train.shape, \"Test shape:\", test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:08.884118Z","iopub.execute_input":"2025-12-01T21:21:08.884640Z","iopub.status.idle":"2025-12-01T21:21:08.921136Z","shell.execute_reply.started":"2025-12-01T21:21:08.884619Z","shell.execute_reply":"2025-12-01T21:21:08.920517Z"}},"outputs":[{"name":"stdout","text":"Train shape: (6827, 8) Test shape: (1707, 2)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"contraction_map = {\n    \"n't\":\" not\", \"'re\":\" are\", \"'s\":\" is\", \"'d\":\" would\", \"'ll\":\" will\", \"'ve\":\" have\", \"'m\":\" am\"\n}\n\ndef basic_text_preprocessing(text):\n    if pd.isna(text):\n        return \"\"\n    s = html.unescape(str(text))\n    s = s.lower()\n\n    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n    s = re.sub(r\"@\\w+\", \" \", s)\n    s = re.sub(r\"#(\\w+)\", r\"\\1\", s)\n    s = re.sub(r\"[^a-z0-9!?'\\s]\", \" \", s)\n\n    \n    s = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", s)\n\n    \n    s = re.sub(r\"\\s+\", \" \", s).strip()\n\n    return s\n\n\n\ntrain[\"clean_text\"] = train[\"text\"].apply(basic_text_preprocessing)\ntest[\"clean_text\"]  = test[\"text\"].apply(basic_text_preprocessing)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:10.131914Z","iopub.execute_input":"2025-12-01T21:21:10.132749Z","iopub.status.idle":"2025-12-01T21:21:10.296982Z","shell.execute_reply.started":"2025-12-01T21:21:10.132721Z","shell.execute_reply":"2025-12-01T21:21:10.296406Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## VOCAB + ENCODING","metadata":{}},{"cell_type":"code","source":"def build_vocab(texts, min_freq=CFG.min_freq):\n    freq = defaultdict(int)\n    for t in texts:\n        for w in t.split():\n            freq[w] += 1\n    vocab = {\"<pad>\":0, \"<unk>\":1}\n    for w,c in sorted(freq.items(), key=lambda x: -x[1]):\n        if c >= min_freq:\n            vocab[w] = len(vocab)\n    return vocab\n\nvocab = build_vocab(train[\"clean_text\"].values, min_freq=CFG.min_freq)\nvocab_size = len(vocab)\nprint(\"Vocab size:\", vocab_size)\n\ndef encode(text, max_len=CFG.max_len):\n    tokens = text.split()\n    ids = [vocab.get(w, vocab[\"<unk>\"]) for w in tokens[:max_len]]\n    if len(ids) < max_len:\n        ids += [vocab[\"<pad>\"]] * (max_len - len(ids))\n    return ids\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:21:11.488635Z","iopub.execute_input":"2025-12-01T21:21:11.489458Z","iopub.status.idle":"2025-12-01T21:22:41.638685Z","shell.execute_reply.started":"2025-12-01T21:21:11.489427Z","shell.execute_reply":"2025-12-01T21:22:41.637764Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 5510\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Data loader","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(train, test_size=0.1, random_state=CFG.seed, shuffle=True, stratify=None)\n\ntrain_df = train_df.reset_index(drop=True)\nval_df   = val_df.reset_index(drop=True)\n\ntrain_df[\"input_ids\"] = train_df[\"clean_text\"].apply(lambda x: encode(x, CFG.max_len))\nval_df[\"input_ids\"]   = val_df[\"clean_text\"].apply(lambda x: encode(x, CFG.max_len))\ntest[\"input_ids\"]     = test[\"clean_text\"].apply(lambda x: encode(x, CFG.max_len))\n\nclass EmotionDataset(Dataset):\n    def __init__(self, df, targets=True):\n        self.ids = df[\"input_ids\"].tolist()\n        self.targets = df[TARGET_COLS].values.astype(\"float32\") if targets else None\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.ids[idx], dtype=torch.long)\n        if self.targets is None:\n            return x\n        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n        return x, y\n\ntrain_dataset = EmotionDataset(train_df, targets=True)\nval_dataset   = EmotionDataset(val_df, targets=True)\ntest_dataset  = EmotionDataset(test, targets=False)\n\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2, pin_memory=True)\ntest_loader  = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:22:41.640301Z","iopub.execute_input":"2025-12-01T21:22:41.640815Z","iopub.status.idle":"2025-12-01T21:22:41.714799Z","shell.execute_reply.started":"2025-12-01T21:22:41.640787Z","shell.execute_reply":"2025-12-01T21:22:41.714149Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## MODEL ARCHITECTURE — Scratch BiLSTM","metadata":{}},{"cell_type":"code","source":"class ScratchBiLSTMAttn(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, \n                 num_layers=1, dropout=0.4, num_heads=4 ):\n        super().__init__()\n\n        # Embedding\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n\n        \n        self.spatial_dropout = nn.Dropout2d(dropout)\n\n        # BiLSTM\n        self.lstm = nn.LSTM(\n            embed_dim,\n            hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        \n        self.gru = nn.GRU(\n            hidden_dim * 2,\n            hidden_dim,\n            num_layers=1,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        # Multi-Head Attention\n        self.mha = nn.MultiheadAttention(\n            embed_dim=hidden_dim * 2,\n            num_heads=num_heads,\n            batch_first=True\n        )\n\n        self.norm1 = nn.LayerNorm(hidden_dim * 2)\n        self.norm2 = nn.LayerNorm(hidden_dim * 2)\n\n        self.dropout = nn.Dropout(dropout)\n\n        \n        self.fc = nn.Linear(hidden_dim * 4, num_labels)\n\n    def forward(self, input_ids):\n        x = self.embedding(input_ids)\n\n        \n        x = self.spatial_dropout(x.unsqueeze(0)).squeeze(0)\n\n        # LSTM\n        out, _ = self.lstm(x)\n        out = self.norm1(out)\n\n        # GRU (stacked)\n        out, _ = self.gru(out)\n        out = self.norm2(out)\n\n        # Attention\n        att_out, _ = self.mha(out, out, out)\n        out = out + att_out\n\n        # Pooling\n        avg_pool = torch.mean(out, 1)\n        max_pool, _ = torch.max(out, 1)\n\n        out = torch.cat((avg_pool, max_pool), dim=1)\n\n        out = self.dropout(out)\n        logits = self.fc(out)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:22:41.715665Z","iopub.execute_input":"2025-12-01T21:22:41.715892Z","iopub.status.idle":"2025-12-01T21:22:41.724119Z","shell.execute_reply.started":"2025-12-01T21:22:41.715875Z","shell.execute_reply":"2025-12-01T21:22:41.723420Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model = ScratchBiLSTMAttn(\n    vocab_size=len(vocab),\n    embed_dim=CFG.embedding_dim,\n    hidden_dim=CFG.hidden_dim,\n    num_labels=len(TARGET_COLS),\n    num_layers=CFG.num_layers,\n    num_heads=CFG.num_heads,\n    dropout=CFG.dropout\n).to(CFG.device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LOSS FUNCTION + OPTIMIZER","metadata":{}},{"cell_type":"code","source":"label_counts = train[TARGET_COLS].sum().values + 1e-6\npos_weight = torch.tensor((len(train) - label_counts) / (label_counts + 1e-6), dtype=torch.float32).to(CFG.device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:01.049505Z","iopub.execute_input":"2025-12-01T21:23:01.049789Z","iopub.status.idle":"2025-12-01T21:23:01.057160Z","shell.execute_reply.started":"2025-12-01T21:23:01.049768Z","shell.execute_reply":"2025-12-01T21:23:01.056494Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\ndef get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, last_epoch=-1):\n    \n    def lr_lambda(current_step):\n        if current_step < num_warmup_steps:\n            return float(current_step) / max(1.0, float(num_warmup_steps))\n        progress = float(current_step - num_warmup_steps) / max(1, float(num_training_steps - num_warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n\ntotal_steps = int(len(train_loader) * CFG.epochs)\nscheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=CFG.warmup_steps, num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:03.592954Z","iopub.execute_input":"2025-12-01T21:23:03.593282Z","iopub.status.idle":"2025-12-01T21:23:03.599991Z","shell.execute_reply.started":"2025-12-01T21:23:03.593229Z","shell.execute_reply":"2025-12-01T21:23:03.599197Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Wandb log","metadata":{}},{"cell_type":"code","source":"wandb.init(project=CFG.project, name=CFG.run_name, config={\n    \"model\": \"ScratchBiLSTMAttn\",\n    \"vocab_size\": vocab_size,\n    \"embedding_dim\": CFG.embedding_dim,\n    \"hidden_dim\": CFG.hidden_dim,\n    \"num_layers\": CFG.num_layers,\n    \"num_heads\": CFG.num_heads,\n    \"batch_size\": CFG.batch_size,\n    \"lr\": CFG.lr,\n    \"epochs\": CFG.epochs,\n    \"max_len\": CFG.max_len\n})\nwandb.watch(model, log=\"all\", log_freq=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:55:15.214069Z","iopub.execute_input":"2025-12-01T20:55:15.214755Z","iopub.status.idle":"2025-12-01T20:55:29.569194Z","shell.execute_reply.started":"2025-12-01T20:55:15.214732Z","shell.execute_reply":"2025-12-01T20:55:29.568621Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhisheksaha\u001b[0m (\u001b[33mabhisheksahaiitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251201_205522-j16wnvua</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/j16wnvua' target=\"_blank\">scratch-bilstm-v2</a></strong> to <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/j16wnvua' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/j16wnvua</a>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Training and validation","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, scheduler, device):\n    model.train()\n    running_loss = 0.0\n    for batch in tqdm(loader, desc=\"Train\"):\n        x, y = batch\n        x = x.to(device)\n        y = y.to(device)\n        logits = model(x)\n        loss = criterion(logits, y)\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), CFG.clip_grad)\n        optimizer.step()\n        scheduler.step()\n        running_loss += loss.item()\n    return running_loss / len(loader)\n\ndef evaluate(model, loader, device):\n    model.eval()\n    total_loss = 0.0\n    preds_list = []\n    labels_list = []\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Val\"):\n            x, y = batch\n            x = x.to(device)\n            y = y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            total_loss += loss.item()\n            probs = torch.sigmoid(logits).cpu().numpy()\n            preds_list.append(probs)\n            labels_list.append(y.cpu().numpy())\n    preds = np.vstack(preds_list)\n    labels = np.vstack(labels_list)\n\n    # find best threshold per class by searching\n    best_thresholds = []\n    best_f1s = {}\n    for i, col in enumerate(TARGET_COLS):\n        best_f1 = 0.0\n        best_t = 0.5\n        for t in np.linspace(0.1, 0.9, 17):\n            pbin = (preds[:, i] > t).astype(int)\n            f1 = f1_score(labels[:, i], pbin, zero_division=0)\n            if f1 > best_f1:\n                best_f1 = f1\n                best_t = t\n        best_thresholds.append(best_t)\n        best_f1s[col] = best_f1\n\n    macro_f1 = np.mean(list(best_f1s.values()))\n    return total_loss / len(loader), macro_f1, best_f1s, best_thresholds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:36.789179Z","iopub.execute_input":"2025-12-01T21:23:36.789939Z","iopub.status.idle":"2025-12-01T21:23:36.798186Z","shell.execute_reply.started":"2025-12-01T21:23:36.789917Z","shell.execute_reply":"2025-12-01T21:23:36.797450Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"best_f1 = -1.0\nbest_thresholds = [0.5] * len(TARGET_COLS)\n\nfor epoch in range(CFG.epochs):\n    start = time.time()\n    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, CFG.device)\n    val_loss, val_macro_f1, per_f1s, thresholds = evaluate(model, val_loader, CFG.device)\n\n    elapsed = time.time() - start\n    print(f\"Epoch {epoch+1}/{CFG.epochs} - train_loss: {train_loss:.4f} val_loss: {val_loss:.4f} val_macro_f1: {val_macro_f1:.4f} time: {elapsed:.1f}s\")\n    print(\"Per-class F1:\", per_f1s)\n    print(\"Thresholds:\", thresholds)\n\n    # W&B logging\n    log_dict = {\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n        \"val_macro_f1\": val_macro_f1,\n        \"lr\": scheduler.get_last_lr()[0]\n    }\n    for k,v in per_f1s.items():\n        log_dict[f\"f1_{k}\"] = v\n    for i,t in enumerate(thresholds):\n        log_dict[f\"thr_{TARGET_COLS[i]}\"] = float(t)\n\n    wandb.log(log_dict)\n\n    # save best\n    if val_macro_f1 > best_f1:\n        best_f1 = val_macro_f1\n        best_thresholds = thresholds\n        torch.save({\n            \"model_state_dict\": model.state_dict(),\n            \"vocab\": vocab,\n            \"best_thresholds\": best_thresholds,\n            \"config\": CFG.__dict__,\n            \"best_f1\": best_f1\n        }, CFG.save_path)\n        print(f\"Saved new best model with F1: {best_f1:.4f}\")\n\n# final log\nwandb.log({\"best_val_f1\": best_f1})\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:55:29.580012Z","iopub.execute_input":"2025-12-01T20:55:29.580218Z","iopub.status.idle":"2025-12-01T20:57:42.342223Z","shell.execute_reply.started":"2025-12-01T20:55:29.580204Z","shell.execute_reply":"2025-12-01T20:57:42.341185Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0337930374eb40e69edc61db9a6fb2ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb3ba3d32a634cdfba633b682d5d0a1d"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/12 - train_loss: 1.2672 val_loss: 1.3606 val_macro_f1: 0.4676 time: 10.3s\nPer-class F1: {'anger': 0.2542372881355932, 'fear': 0.7293023255813954, 'joy': 0.38534278959810875, 'sadness': 0.47032474804031354, 'surprise': 0.4985590778097983}\nThresholds: [0.85, 0.1, 0.1, 0.1, 0.9]\nSaved new best model with F1: 0.4676\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccee48ab22d141fc8f75243718f27838"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nException ignored in: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n    Traceback (most recent call last):\nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nif w.is_alive():\n     if w.is_alive():   \n     ^ ^^ ^^ ^ ^^ ^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^^  ^^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n     ^  ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^^: ^can only test a child process^\n^\nAssertionError: Exception ignored in: can only test a child process\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()\n    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n     if w.is_alive():  \n         ^  ^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'\n             ^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: \ncan only test a child process\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194b55b7c16a488ea19ccb83d796b938"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/12 - train_loss: 1.0935 val_loss: 0.9674 val_macro_f1: 0.5232 time: 10.1s\nPer-class F1: {'anger': 0.3571428571428571, 'fear': 0.7317073170731706, 'joy': 0.42888402625820565, 'sadness': 0.48049921996879874, 'surprise': 0.6179245283018867}\nThresholds: [0.6, 0.30000000000000004, 0.45000000000000007, 0.15000000000000002, 0.9]\nSaved new best model with F1: 0.5232\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c6686e03844d28a6409780667c9a0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6953e9b4ff2b46fc8a4659be15cbc642"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/12 - train_loss: 0.8223 val_loss: 0.8032 val_macro_f1: 0.5863 time: 10.1s\nPer-class F1: {'anger': 0.45833333333333337, 'fear': 0.7522211253701876, 'joy': 0.5025641025641027, 'sadness': 0.5750915750915752, 'surprise': 0.6434426229508197}\nThresholds: [0.8, 0.5, 0.4, 0.35, 0.55]\nSaved new best model with F1: 0.5863\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4720a2446a4d4cbf96af67d247112527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3929a7c0871a4523a5eb033f6b99bcac"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/12 - train_loss: 0.5937 val_loss: 0.7386 val_macro_f1: 0.6638 time: 10.4s\nPer-class F1: {'anger': 0.6134969325153374, 'fear': 0.7752928647497338, 'joy': 0.6261980830670926, 'sadness': 0.6360153256704981, 'surprise': 0.6679920477137177}\nThresholds: [0.8, 0.25, 0.75, 0.30000000000000004, 0.4]\nSaved new best model with F1: 0.6638\n","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n    Traceback (most recent call last):\nself._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        if w.is_alive():self._shutdown_workers()\n\n ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b91174f99be4f0597dd7ac16eb923ec"}},"metadata":{}},{"name":"stderr","text":"  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n      if w.is_alive(): \n        ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError\n: can only test a child processAssertionError\n: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e6ebf416fb4ae8ab814cf831c77866"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/12 - train_loss: 0.4533 val_loss: 0.8126 val_macro_f1: 0.6768 time: 10.8s\nPer-class F1: {'anger': 0.6296296296296297, 'fear': 0.7694038245219347, 'joy': 0.6588921282798834, 'sadness': 0.6349206349206349, 'surprise': 0.6909871244635192}\nThresholds: [0.8, 0.35, 0.7000000000000001, 0.6, 0.6]\nSaved new best model with F1: 0.6768\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a31841a83b145e1abbd94dd2b1ff6d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2923c8f3d264f78a9ac8b98df708d6e"}},"metadata":{}},{"name":"stdout","text":"Epoch 6/12 - train_loss: 0.3325 val_loss: 0.9117 val_macro_f1: 0.7098 time: 11.2s\nPer-class F1: {'anger': 0.6625, 'fear': 0.7816349384098543, 'joy': 0.7055016181229773, 'sadness': 0.6870588235294117, 'surprise': 0.7122641509433962}\nThresholds: [0.9, 0.2, 0.8, 0.75, 0.4]\nSaved new best model with F1: 0.7098\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc3c290b98254abfaa96bee517f23a90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8491d14ef70e4764b7eb26adb91a4552"}},"metadata":{}},{"name":"stdout","text":"Epoch 7/12 - train_loss: 0.2465 val_loss: 0.9451 val_macro_f1: 0.7179 time: 11.7s\nPer-class F1: {'anger': 0.6666666666666667, 'fear': 0.7842278203723987, 'joy': 0.6964856230031949, 'sadness': 0.7119341563786008, 'surprise': 0.730310262529833}\nThresholds: [0.9, 0.25, 0.9, 0.25, 0.75]\nSaved new best model with F1: 0.7179\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c89e0ecf029045c480c9e4942975a6ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c223ef9ef1a14d3290a8bf6f656bed1e"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n    Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():    \nif w.is_alive(): \n            ^ ^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\n: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nException ignored in:     self._shutdown_workers()\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    if w.is_alive():\n     self._shutdown_workers()\n    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n     if w.is_alive():\n     ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n\nException ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>: \ncan only test a child process\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nself._shutdown_workers()\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n\n             ^ ^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                    ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n^\nException ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>: \ncan only test a child process\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    Exception ignored in: self._shutdown_workers()\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nTraceback (most recent call last):\n    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n       self._shutdown_workers() \n     File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    if w.is_alive():^^\n^^ ^ ^ ^ ^ ^  ^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^  ^ ^ ^ \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^  ^ ^^ ^  ^ ^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^^can only test a child process^\n^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    self._shutdown_workers()\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():^\n\nAssertionError : can only test a child process \n    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680> \n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^^if w.is_alive():^\n ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n   ^  ^ ^ ^^  ^ ^ ^^ ^ ^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^^can only test a child process^\n^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>^^^\n^^^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n    if w.is_alive():AssertionError\n: can only test a child process \n  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680> \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    ^if w.is_alive():^\n^ ^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^^  ^ ^ ^ ^ ^ ^ \n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^ ^^ ^ ^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: can only test a child process^\n^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    ^if w.is_alive():^^\n\nAssertionError:  can only test a child process\n Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680> \n Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n     self._shutdown_workers() \n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    ^if w.is_alive():^\n^ ^ ^ ^^  ^ ^ \n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n^ ^  ^^  ^ ^ ^ ^\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^^  ^ ^^  ^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^^: ^can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n^Traceback (most recent call last):\n^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    AssertionError: can only test a child processself._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>if w.is_alive():\n \nTraceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n       self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^^if w.is_alive():^\n^ ^  ^^ ^  ^ ^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n  ^^  ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^can only test a child process^\n^^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n\nAssertionErrorTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n:     can only test a child processself._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>if w.is_alive():\n\n  Traceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n      self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^if w.is_alive():^\n^ ^ ^ ^ ^^ ^ ^ ^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^^ ^ ^  ^ ^ \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process' \n^ ^ ^  ^ ^ ^ ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^^: ^can only test a child process^\n^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nTraceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    ^self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nAssertionError    : if w.is_alive():\n can only test a child process  \n   Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>^\nTraceback (most recent call last):\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    ^if w.is_alive():^\n\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n     ^  ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^  ^ ^ ^ ^ ^ ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()^\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^^^if w.is_alive():\n^ ^\n AssertionError:  can only test a child process \n Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()^^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    ^if w.is_alive():^\n^^\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process' \n            ^^^  ^ ^ ^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^  ^ ^ ^^  ^^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^\nAssertionError^: ^can only test a child process^\n^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/12 - train_loss: 0.1819 val_loss: 1.1010 val_macro_f1: 0.7218 time: 13.1s\nPer-class F1: {'anger': 0.6754966887417218, 'fear': 0.7902439024390243, 'joy': 0.7028753993610223, 'sadness': 0.7180616740088107, 'surprise': 0.7221006564551423}\nThresholds: [0.9, 0.5, 0.75, 0.5, 0.30000000000000004]\nSaved new best model with F1: 0.7218\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c86ac5ee6386403cbb3892f896bc16b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe6e41d90e941b792b1004d938fc009"}},"metadata":{}},{"name":"stdout","text":"Epoch 9/12 - train_loss: 0.1362 val_loss: 1.4648 val_macro_f1: 0.7365 time: 10.9s\nPer-class F1: {'anger': 0.7083333333333333, 'fear': 0.800976800976801, 'joy': 0.719242902208202, 'sadness': 0.7247706422018347, 'surprise': 0.7290640394088669}\nThresholds: [0.65, 0.35, 0.85, 0.5, 0.65]\nSaved new best model with F1: 0.7365\n","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680><function _MultiProcessingDataLoaderIter.__del__ at 0x7a6ef4d80680>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():    if w.is_alive():\n\n            ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e34eb45a669049c598cdf0309845df56"}},"metadata":{}},{"name":"stderr","text":"  ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^\n    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^can only test a child process\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf82e9fc8d3d492995b6f7f56ece8d94"}},"metadata":{}},{"name":"stdout","text":"Epoch 10/12 - train_loss: 0.1016 val_loss: 1.6028 val_macro_f1: 0.7384 time: 10.8s\nPer-class F1: {'anger': 0.7096774193548386, 'fear': 0.8068043742405833, 'joy': 0.7204968944099379, 'sadness': 0.7250608272506083, 'surprise': 0.7297297297297297}\nThresholds: [0.45000000000000007, 0.30000000000000004, 0.8, 0.85, 0.15000000000000002]\nSaved new best model with F1: 0.7384\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd88be590cf4dca82f3806ed480791f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0cf1c773a214f65989dfce561bb345f"}},"metadata":{}},{"name":"stdout","text":"Epoch 11/12 - train_loss: 0.0833 val_loss: 1.9133 val_macro_f1: 0.7413 time: 10.7s\nPer-class F1: {'anger': 0.7000000000000001, 'fear': 0.8133848133848135, 'joy': 0.7261146496815286, 'sadness': 0.7383177570093459, 'surprise': 0.7285067873303168}\nThresholds: [0.85, 0.45000000000000007, 0.85, 0.65, 0.25]\nSaved new best model with F1: 0.7413\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a784583d6f404b93b6105ae18a83ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697405c6ca85460b86a00f9d363b57f8"}},"metadata":{}},{"name":"stdout","text":"Epoch 12/12 - train_loss: 0.0752 val_loss: 1.9292 val_macro_f1: 0.7418 time: 10.8s\nPer-class F1: {'anger': 0.7051282051282051, 'fear': 0.8114143920595533, 'joy': 0.7261146496815286, 'sadness': 0.7370892018779343, 'surprise': 0.7293064876957495}\nThresholds: [0.25, 0.35, 0.8, 0.6, 0.2]\nSaved new best model with F1: 0.7418\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>f1_anger</td><td>▁▃▄▇▇▇▇▇████</td></tr><tr><td>f1_fear</td><td>▁▁▃▅▄▅▆▆▇▇██</td></tr><tr><td>f1_joy</td><td>▁▂▃▆▇█▇█████</td></tr><tr><td>f1_sadness</td><td>▁▁▄▅▅▇▇▇████</td></tr><tr><td>f1_surprise</td><td>▁▅▅▆▇▇██████</td></tr><tr><td>lr</td><td>███▇▆▅▄▃▂▂▁▁</td></tr><tr><td>thr_anger</td><td>▇▅▇▇▇███▅▃▇▁</td></tr><tr><td>thr_fear</td><td>▁▅█▄▅▃▄█▅▅▇▅</td></tr><tr><td>thr_joy</td><td>▁▄▄▇▆▇█▇█▇█▇</td></tr><tr><td>thr_sadness</td><td>▁▁▃▃▆▇▂▅▅█▆▆</td></tr><tr><td>thr_surprise</td><td>██▅▃▅▃▇▂▆▁▂▁</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>▅▂▁▁▁▂▂▃▅▆██</td></tr><tr><td>val_macro_f1</td><td>▁▂▄▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>0.74181</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>f1_anger</td><td>0.70513</td></tr><tr><td>f1_fear</td><td>0.81141</td></tr><tr><td>f1_joy</td><td>0.72611</td></tr><tr><td>f1_sadness</td><td>0.73709</td></tr><tr><td>f1_surprise</td><td>0.72931</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>thr_anger</td><td>0.25</td></tr><tr><td>thr_fear</td><td>0.35</td></tr><tr><td>thr_joy</td><td>0.8</td></tr><tr><td>thr_sadness</td><td>0.6</td></tr><tr><td>thr_surprise</td><td>0.2</td></tr><tr><td>train_loss</td><td>0.07523</td></tr><tr><td>val_loss</td><td>1.92916</td></tr><tr><td>val_macro_f1</td><td>0.74181</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">scratch-bilstm-v2</strong> at: <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/j16wnvua' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/j16wnvua</a><br> View project at: <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251201_205522-j16wnvua/logs</code>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## INFERENCE ON TEST","metadata":{}},{"cell_type":"code","source":"print(\"Loading best model for inference...\")\n\nimport numpy as np\nimport torch.serialization\n\ntorch.serialization.add_safe_globals([np.core.multiarray.scalar])\n\n\nckpt = torch.load(\n    CFG.save_path,\n    map_location=CFG.device,\n    weights_only=False\n)\n\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.to(CFG.device)\nmodel.eval()\n\n\nbest_thresholds = np.array(ckpt.get(\"best_thresholds\", [0.5]*len(TARGET_COLS)))\n\n\nall_preds = []\nwith torch.no_grad():\n    for x in tqdm(test_loader, desc=\"Test\"):\n        x = x.to(CFG.device)\n        logits = model(x)\n        probs = torch.sigmoid(logits).cpu().numpy()\n        all_preds.extend(probs)\n\nall_preds = np.array(all_preds)\nbinary_preds = (all_preds > best_thresholds).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:02:09.374710Z","iopub.execute_input":"2025-12-01T21:02:09.375457Z","iopub.status.idle":"2025-12-01T21:02:10.627481Z","shell.execute_reply.started":"2025-12-01T21:02:09.375415Z","shell.execute_reply":"2025-12-01T21:02:10.626544Z"}},"outputs":[{"name":"stdout","text":"Loading best model for inference...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Test:   0%|          | 0/27 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7dd0b8a50b4ce6bb03384c1d7e2b71"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"anger\": binary_preds[:,0],\n    \"fear\": binary_preds[:,1],\n    \"joy\": binary_preds[:,2],\n    \"sadness\": binary_preds[:,3],\n    \"surprise\": binary_preds[:,4],\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission_scratch_bilstm.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:02:14.038230Z","iopub.execute_input":"2025-12-01T21:02:14.039121Z","iopub.status.idle":"2025-12-01T21:02:14.058486Z","shell.execute_reply.started":"2025-12-01T21:02:14.039078Z","shell.execute_reply":"2025-12-01T21:02:14.057619Z"}},"outputs":[{"name":"stdout","text":"Saved submission_scratch_bilstm.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}

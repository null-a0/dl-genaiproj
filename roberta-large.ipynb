{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":115439,"databundleVersionId":13800781,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DL-GENAi PROJECT ‚Äî DistilRoBERTa-Base\n# Name  : Abhishek Saha\n# Roll  : 23f1001572\n# Model : roberta-large\n","metadata":{}},{"cell_type":"markdown","source":"## IMPORTS AND SETUP","metadata":{}},{"cell_type":"code","source":"!wandb login 20d9b18a55f275c39d05bf53e51e8b328aeffff5\n\nimport pandas as pd\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    AutoConfig,\n    get_linear_schedule_with_warmup\n)\n\nfrom tqdm.auto import tqdm\nimport warnings, logging\n\nwarnings.filterwarnings(\"ignore\")\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\nlogging.getLogger(\"tokenizers\").setLevel(logging.ERROR)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:25.044862Z","iopub.execute_input":"2025-12-01T19:20:25.045079Z","iopub.status.idle":"2025-12-01T19:20:44.520375Z","shell.execute_reply.started":"2025-12-01T19:20:25.045055Z","shell.execute_reply":"2025-12-01T19:20:44.519540Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\nUsing device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## CONFIGURATION","metadata":{}},{"cell_type":"code","source":"class Config:\n    model_name    = \"roberta-large\"   \n    max_length    = 256               \n    batch_size    = 8                 \n    learning_rate = 1e-5              \n    epochs        = 5                 \n    warmup_steps  = 200               \n    grad_accum    = 2                 \n    focal_loss_gamma = 2.0\n    dropout_rate  = 0.3\n    weight_decay  = 0.01\n    seed          = 42\n    augmentation  = True\n\n    project = \"23f1001572-t32025\"\n    run_name = \"roberta-large-final\"\nCFG = Config()\n\nTARGET_COLS = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:44.521764Z","iopub.execute_input":"2025-12-01T19:20:44.522196Z","iopub.status.idle":"2025-12-01T19:20:44.527343Z","shell.execute_reply.started":"2025-12-01T19:20:44.522172Z","shell.execute_reply":"2025-12-01T19:20:44.525999Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## REPRODUCIBILITY","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(CFG.seed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:44.530502Z","iopub.execute_input":"2025-12-01T19:20:44.530746Z","iopub.status.idle":"2025-12-01T19:20:44.559396Z","shell.execute_reply.started":"2025-12-01T19:20:44.530723Z","shell.execute_reply":"2025-12-01T19:20:44.558866Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## DATA LOADING","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/2025-sep-dl-gen-ai-project/train.csv\"\nTEST_PATH  = \"/kaggle/input/2025-sep-dl-gen-ai-project/test.csv\"\n\ntrain = pd.read_csv(TRAIN_PATH)\ntest  = pd.read_csv(TEST_PATH)\n\nprint(train.shape, test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:49.590682Z","iopub.execute_input":"2025-12-01T19:20:49.591010Z","iopub.status.idle":"2025-12-01T19:20:49.655244Z","shell.execute_reply.started":"2025-12-01T19:20:49.590980Z","shell.execute_reply":"2025-12-01T19:20:49.654634Z"}},"outputs":[{"name":"stdout","text":"(6827, 8) (1707, 2)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## TEXT PREPROCESSING","metadata":{}},{"cell_type":"code","source":"import re, html\n\ndef basic_text_preprocessing(text):\n    if pd.isna(text):\n        return \"\"\n    s = html.unescape(str(text))\n    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n    s = re.sub(r\"@\\w+\", \" \", s)\n    s = re.sub(r\"#(\\w+)\", r\"\\1\", s)\n    s = re.sub(r\"[^A-Za-z0-9\\s!?']\", \" \", s)\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s.lower()\n\ndef simple_augmentation(text, p=0.1):\n    if random.random() > p: return text\n    words = text.split()\n    if len(words) < 2: return text\n    idx = random.randint(0, len(words)-2)\n    words[idx], words[idx+1] = words[idx+1], words[idx]\n    return \" \".join(words)\n\ntrain[\"text_processed\"] = train[\"text\"].apply(basic_text_preprocessing)\ntest[\"text_processed\"]  = test[\"text\"].apply(basic_text_preprocessing)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:21:35.293708Z","iopub.execute_input":"2025-12-01T19:21:35.294013Z","iopub.status.idle":"2025-12-01T19:21:35.397556Z","shell.execute_reply.started":"2025-12-01T19:21:35.293990Z","shell.execute_reply":"2025-12-01T19:21:35.397041Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## DATASET CLASS","metadata":{}},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, texts, labels=None, tokenizer=None, max_length=128, augment=False):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_length\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        if self.augment and self.labels is not None:\n            text = simple_augmentation(text)\n\n        enc = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n\n        item = {\n            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.FloatTensor(self.labels[idx])\n        return item\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:21:38.559503Z","iopub.execute_input":"2025-12-01T19:21:38.560053Z","iopub.status.idle":"2025-12-01T19:21:38.565374Z","shell.execute_reply.started":"2025-12-01T19:21:38.560029Z","shell.execute_reply":"2025-12-01T19:21:38.564792Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## MODEL ARCHITECTURE","metadata":{}},{"cell_type":"code","source":"class EmotionClassifier(nn.Module):\n    def __init__(self, model_name, num_labels=5, dropout_rate=0.3):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.transformer = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        out = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        cls = out.last_hidden_state[:, 0, :]\n        cls = self.dropout(cls)\n        logits = self.classifier(cls)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:21:46.220061Z","iopub.execute_input":"2025-12-01T19:21:46.220384Z","iopub.status.idle":"2025-12-01T19:21:46.226375Z","shell.execute_reply.started":"2025-12-01T19:21:46.220361Z","shell.execute_reply":"2025-12-01T19:21:46.225648Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## LOSS FUNCTION","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0):\n        super().__init__()\n        self.gamma = gamma\n\n    def forward(self, logits, targets):\n        bce = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n        pt = torch.exp(-bce)\n        loss = ((1 - pt)**self.gamma) * bce\n        return loss.mean()\n\ncriterion = FocalLoss(gamma=CFG.focal_loss_gamma)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:22:03.256369Z","iopub.execute_input":"2025-12-01T19:22:03.256644Z","iopub.status.idle":"2025-12-01T19:22:03.261418Z","shell.execute_reply.started":"2025-12-01T19:22:03.256623Z","shell.execute_reply":"2025-12-01T19:22:03.260651Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## TRAIN FUNCTION","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, scheduler, device, epoch):\n    model.train()\n    total_loss = 0.0\n    optimizer.zero_grad()\n\n    for step, batch in enumerate(tqdm(loader, desc=f\"Training Epoch {epoch+1}\")):\n\n        ids   = batch[\"input_ids\"].to(device)\n        mask  = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        logits = model(ids, mask)\n        loss   = criterion(logits, labels)\n\n        loss.backward()\n\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:22:26.537454Z","iopub.execute_input":"2025-12-01T19:22:26.538058Z","iopub.status.idle":"2025-12-01T19:22:26.545641Z","shell.execute_reply.started":"2025-12-01T19:22:26.538026Z","shell.execute_reply":"2025-12-01T19:22:26.544802Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## VALIDATION FUNCTION","metadata":{}},{"cell_type":"code","source":"def validate_epoch(model, loader, device, epoch):\n    model.eval()\n    val_loss = 0.0\n    preds, labels_list = [], []\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=f\"Validation Epoch {epoch+1}\"):\n\n            ids   = batch[\"input_ids\"].to(device)\n            mask  = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            logits = model(ids, mask)\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n\n            probs = torch.sigmoid(logits).cpu().numpy()\n            preds.extend(probs)\n            labels_list.extend(labels.cpu().numpy())\n\n    preds = np.array(preds)\n    labels_list = np.array(labels_list)\n\n    bin_preds = (preds > 0.5).astype(int)\n\n    f1_scores = {emo: f1_score(labels_list[:, i], bin_preds[:, i]) \n                 for i, emo in enumerate(TARGET_COLS)}\n\n    macro_f1 = np.mean(list(f1_scores.values()))\n\n    return macro_f1, val_loss / len(loader), f1_scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:22:37.446506Z","iopub.execute_input":"2025-12-01T19:22:37.447239Z","iopub.status.idle":"2025-12-01T19:22:37.453067Z","shell.execute_reply.started":"2025-12-01T19:22:37.447215Z","shell.execute_reply":"2025-12-01T19:22:37.452422Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## DATA PREP","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(train, test_size=0.1, random_state=CFG.seed)\n\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n\ntrain_dataset = EmotionDataset(\n    train_df[\"text_processed\"].values,\n    train_df[TARGET_COLS].values,\n    tokenizer,\n    max_length=CFG.max_length,\n    augment=CFG.augmentation\n)\n\nval_dataset = EmotionDataset(\n    val_df[\"text_processed\"].values,\n    val_df[TARGET_COLS].values,\n    tokenizer,\n    max_length=CFG.max_length,\n    augment=False\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:22:50.600488Z","iopub.execute_input":"2025-12-01T19:22:50.601112Z","iopub.status.idle":"2025-12-01T19:22:52.082853Z","shell.execute_reply.started":"2025-12-01T19:22:50.601090Z","shell.execute_reply":"2025-12-01T19:22:52.082063Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2ab6e8f22f402b88ebe949f06a24b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e6614aa6344249bce510d294778ca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5294c0fb7b734f0ea22ea14b6df4b182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"096341d65a0046e2abdef25bc7b21e6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4a0d76f59184cd7b43036bd0cc8744f"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## MODEL INIT","metadata":{}},{"cell_type":"code","source":"model = EmotionClassifier(CFG.model_name, num_labels=len(TARGET_COLS), dropout_rate=CFG.dropout_rate)\nmodel.to(DEVICE)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n\ntotal_steps = len(train_loader) * CFG.epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=CFG.warmup_steps,\n    num_training_steps=total_steps\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:23:07.634666Z","iopub.execute_input":"2025-12-01T19:23:07.635411Z","iopub.status.idle":"2025-12-01T19:23:49.233484Z","shell.execute_reply.started":"2025-12-01T19:23:07.635376Z","shell.execute_reply":"2025-12-01T19:23:49.232623Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 19:23:15.502854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764616995.895584      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764616996.027144      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb07db355e044268b3bc2bda69543535"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## wandb init","metadata":{}},{"cell_type":"code","source":"import wandb\n\nwandb.init(\n    project=CFG.project,\n    name=CFG.run_name,\n    config=CFG.__dict__\n)\n\nwandb.watch(model, log_freq=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:23:49.234749Z","iopub.execute_input":"2025-12-01T19:23:49.235477Z","iopub.status.idle":"2025-12-01T19:24:03.308058Z","shell.execute_reply.started":"2025-12-01T19:23:49.235456Z","shell.execute_reply":"2025-12-01T19:24:03.307315Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhisheksaha\u001b[0m (\u001b[33mabhisheksahaiitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251201_192356-3guza3au</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/3guza3au' target=\"_blank\">roberta-large-final</a></strong> to <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/3guza3au' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/3guza3au</a>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## TRAIN LOOP","metadata":{}},{"cell_type":"code","source":"best_f1 = 0.0\n\nfor epoch in range(CFG.epochs):\n    print(f\"\\nEpoch {epoch+1}/{CFG.epochs}\")\n\n    train_loss = train_epoch(model, train_loader, optimizer, scheduler, DEVICE, epoch)\n    val_f1, val_loss, emo_f1s = validate_epoch(model, val_loader, DEVICE, epoch)\n\n    print(\"Train Loss:\", train_loss)\n    print(\"Val Loss:\", val_loss)\n    print(\"Val F1:\", val_f1)\n    print(\"Per Emotion:\", emo_f1s)\n\n    log_data = {\n        \"epoch\": epoch+1,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n        \"val_macro_f1\": val_f1\n    }\n    for k,v in emo_f1s.items():\n        log_data[f\"f1_{k}\"] = v\n\n    wandb.log(log_data)\n\n    if val_f1 > best_f1:\n        torch.save(model.state_dict(), \"best_model.pth\")\n        best_f1 = val_f1\n        print(\" New best model saved\")\n\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:25:43.358249Z","iopub.execute_input":"2025-12-01T19:25:43.358899Z","iopub.status.idle":"2025-12-01T20:43:19.953679Z","shell.execute_reply.started":"2025-12-01T19:25:43.358878Z","shell.execute_reply":"2025-12-01T20:43:19.952803Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 1:   0%|          | 0/768 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e814ec416cb46cca4e9c2a2aec0ea38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 1:   0%|          | 0/86 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3618027f0f1f4c0c80533ec0a1959fe5"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.13162195727151507\nVal Loss: 0.0822086225285433\nVal F1: 0.7263431148440889\nPer Emotion: {'anger': 0.6466165413533834, 'fear': 0.8689320388349514, 'joy': 0.7147766323024056, 'sadness': 0.6883468834688347, 'surprise': 0.7130434782608694}\nüî• New best model saved\n\nEpoch 2/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 2:   0%|          | 0/768 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5056fa0eb60f40928be2b6b1b3b6b39b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 2:   0%|          | 0/86 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3612446c84a54cc1a81d9d32a4295d7b"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0783418577023743\nVal Loss: 0.07184008461271607\nVal F1: 0.8211575275931473\nPer Emotion: {'anger': 0.7712418300653595, 'fear': 0.8675675675675676, 'joy': 0.8038585209003215, 'sadness': 0.8284313725490196, 'surprise': 0.8346883468834688}\nüî• New best model saved\n\nEpoch 3/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 3:   0%|          | 0/768 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7823a7f72ea34585a9b46af9e104174d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 3:   0%|          | 0/86 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0443531934f408bbc6f36d4d794c154"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.05027232604152232\nVal Loss: 0.07020375485055495\nVal F1: 0.8413627819397312\nPer Emotion: {'anger': 0.7814569536423841, 'fear': 0.9051833122629582, 'joy': 0.8074534161490682, 'sadness': 0.8433734939759037, 'surprise': 0.8693467336683418}\nüî• New best model saved\n\nEpoch 4/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 4:   0%|          | 0/768 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741a2de248b4444ca65438c1bb41eb8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 4:   0%|          | 0/86 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f379fd3370064d5b8a59387825bb4401"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.033636351379527696\nVal Loss: 0.08561704498661551\nVal F1: 0.8569932172047885\nPer Emotion: {'anger': 0.8211920529801324, 'fear': 0.9124668435013261, 'joy': 0.8294117647058823, 'sadness': 0.8444444444444444, 'surprise': 0.8774509803921569}\nüî• New best model saved\n\nEpoch 5/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Epoch 5:   0%|          | 0/768 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39870d2b31e4be4ae3134ff942bbbaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 5:   0%|          | 0/86 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a923dbd82ad4555ab62105329b9dafe"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0223057640390986\nVal Loss: 0.09066195616384881\nVal F1: 0.8721339593023945\nPer Emotion: {'anger': 0.8496732026143791, 'fear': 0.9286640726329443, 'joy': 0.8501529051987767, 'sadness': 0.8483412322274881, 'surprise': 0.8838383838383838}\nüî• New best model saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>f1_anger</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà</td></tr><tr><td>f1_fear</td><td>‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>f1_joy</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>f1_sadness</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>f1_surprise</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñà</td></tr><tr><td>val_macro_f1</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>f1_anger</td><td>0.84967</td></tr><tr><td>f1_fear</td><td>0.92866</td></tr><tr><td>f1_joy</td><td>0.85015</td></tr><tr><td>f1_sadness</td><td>0.84834</td></tr><tr><td>f1_surprise</td><td>0.88384</td></tr><tr><td>train_loss</td><td>0.02231</td></tr><tr><td>val_loss</td><td>0.09066</td></tr><tr><td>val_macro_f1</td><td>0.87213</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">roberta-large-final</strong> at: <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/3guza3au' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025/runs/3guza3au</a><br> View project at: <a href='https://wandb.ai/abhisheksahaiitm/23f1001572-t32025' target=\"_blank\">https://wandb.ai/abhisheksahaiitm/23f1001572-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251201_192356-3guza3au/logs</code>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pth\", map_location=DEVICE))\nmodel.to(DEVICE)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:43:19.955094Z","iopub.execute_input":"2025-12-01T20:43:19.955384Z","iopub.status.idle":"2025-12-01T20:43:20.738820Z","shell.execute_reply.started":"2025-12-01T20:43:19.955360Z","shell.execute_reply":"2025-12-01T20:43:20.738235Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"EmotionClassifier(\n  (transformer): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"test_dataset = EmotionDataset(\n    test[\"text_processed\"].values,\n    None,\n    tokenizer=tokenizer,\n    max_length=CFG.max_length,\n    augment=False\n)\n\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n\nall_preds = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Testing\"):\n        ids = batch[\"input_ids\"].to(DEVICE)\n        mask = batch[\"attention_mask\"].to(DEVICE)\n\n        logits = model(ids, mask)\n        probs  = torch.sigmoid(logits).cpu().numpy()\n        all_preds.extend(probs)\n\nall_preds = np.array(all_preds)\nbinary_preds = (all_preds > 0.5).astype(int)\n\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"anger\": binary_preds[:,0],\n    \"fear\": binary_preds[:,1],\n    \"joy\": binary_preds[:,2],\n    \"sadness\": binary_preds[:,3],\n    \"surprise\": binary_preds[:,4]\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:43:20.739497Z","iopub.execute_input":"2025-12-01T20:43:20.739749Z","iopub.status.idle":"2025-12-01T20:44:35.257579Z","shell.execute_reply.started":"2025-12-01T20:43:20.739730Z","shell.execute_reply":"2025-12-01T20:44:35.256880Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee14a0027e164de1b2adfad793bae31a"}},"metadata":{}},{"name":"stdout","text":"Saved submission.csv\n","output_type":"stream"}],"execution_count":17}]}
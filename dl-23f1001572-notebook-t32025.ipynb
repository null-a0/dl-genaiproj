{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":115439,"databundleVersionId":13800781,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":669145,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":506684,"modelId":521448},{"sourceId":669148,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":506687,"modelId":521451},{"sourceId":669214,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":506737,"modelId":521495},{"sourceId":669239,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":506758,"modelId":521512}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Name: Abhishek Saha\n## Roll: 23f1001572  \n## Models Included:\n- Scratch BiLSTM  \n- DistilRoBERTa / DeBERTa  \n- TF-IDF + LightGBM\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport joblib\nimport lightgbm as lgb\nimport re, html\nfrom tqdm import tqdm\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTARGET_COLS = [\"anger\",\"fear\",\"joy\",\"sadness\",\"surprise\"]\n\nTEST_PATH = \"/kaggle/input/2025-sep-dl-gen-ai-project/test.csv\"\ntest_df = pd.read_csv(TEST_PATH)\n\nprint(\"Loaded test shape:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:26:21.778533Z","iopub.execute_input":"2025-12-02T00:26:21.779077Z","iopub.status.idle":"2025-12-02T00:26:26.472653Z","shell.execute_reply.started":"2025-12-02T00:26:21.779053Z","shell.execute_reply":"2025-12-02T00:26:26.472001Z"}},"outputs":[{"name":"stdout","text":"Loaded test shape: (1707, 2)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## TEXT PREPROCESSING","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    text = html.unescape(str(text)).lower()\n    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n    text = re.sub(r\"@\\w+\", \" \", text)\n    text = re.sub(r\"[^a-z0-9\\s\\.\\,\\!\\?\\']\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ntest_df[\"clean_text\"] = test_df[\"text\"].apply(preprocess_text)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:26:27.870431Z","iopub.execute_input":"2025-12-02T00:26:27.871153Z","iopub.status.idle":"2025-12-02T00:26:27.899858Z","shell.execute_reply.started":"2025-12-02T00:26:27.871128Z","shell.execute_reply":"2025-12-02T00:26:27.899177Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## MODEL 1 — SCRATCH BILSTM ATTENTION","metadata":{}},{"cell_type":"code","source":"print(\"\\n=== Loading Model 1 (Scratch BiLSTM) ===\")\n\nckpt1 = torch.load(\n    \"/kaggle/input/abhi-scratch-bilstm/pytorch/default/1/scratch_bilstm.pth\",\n    map_location=DEVICE,\n    weights_only=False\n)\n\nvocab = ckpt1[\"vocab\"]\nthresholds1 = np.array(ckpt1[\"best_thresholds\"])\nsd = ckpt1[\"model_state_dict\"]\n\nemb_shape = sd[\"embedding.weight\"].shape\nvocab_size = emb_shape[0]\nembedding_dim = emb_shape[1]\n\n# LSTM input shape → hidden_dim extraction\nlstm_ih_shape = sd[\"lstm.weight_ih_l0\"].shape  # (4*hidden_dim, embedding_dim)\nhidden_dim = lstm_ih_shape[0] // 4\n\n# Detect number of LSTM layers\nnum_layers = 1\nwhile f\"lstm.weight_ih_l{num_layers}\" in sd:\n    num_layers += 1\n\ndropout = 0.3\n\n\nmax_len = ckpt1.get(\"max_len\", 80)\n\nprint(\"Recovered architecture:\")\nprint(f\" vocab_size={vocab_size}\")\nprint(f\" embedding_dim={embedding_dim}\")\nprint(f\" hidden_dim={hidden_dim}\")\nprint(f\" num_layers={num_layers}\")\nprint(f\" max_len={max_len}\")\n\n\ndef encode(text, max_len=max_len):\n    tokens = text.split()\n    ids = [vocab.get(w, vocab.get(\"<unk>\", 1)) for w in tokens[:max_len]]\n    if len(ids) < max_len:\n        ids += [vocab.get(\"<pad>\", 0)] * (max_len - len(ids))\n    return ids\n\ntest_df[\"input_ids\"] = test_df[\"clean_text\"].apply(lambda x: encode(x))\n\nimport torch.nn as nn\n\nclass ScratchBiLSTMAttn(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels,\n                 num_layers=1, dropout=0.4, num_heads=4):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.spatial_dropout = nn.Dropout2d(dropout)\n\n        \n        self.lstm = nn.LSTM(\n            embed_dim,\n            hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        \n        self.gru = nn.GRU(\n            hidden_dim * 2,        # 768 input to GRU\n            hidden_dim,            # 384 hidden\n            num_layers=1,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        \n        self.mha = nn.MultiheadAttention(\n            embed_dim=hidden_dim * 2, \n            num_heads=num_heads,\n            batch_first=True\n        )\n\n        \n        self.norm1 = nn.LayerNorm(hidden_dim * 2)\n        self.norm2 = nn.LayerNorm(hidden_dim * 2)\n\n        self.dropout = nn.Dropout(dropout)\n\n        \n        self.fc = nn.Linear(hidden_dim * 4, num_labels)\n\n    def forward(self, input_ids):\n        x = self.embedding(input_ids)\n\n        # Spatial dropout\n        x = self.spatial_dropout(x.unsqueeze(0)).squeeze(0)\n\n        # LSTM\n        out, _ = self.lstm(x)\n        out = self.norm1(out)\n\n        # GRU\n        out, _ = self.gru(out)\n        out = self.norm2(out)\n\n        # Attention\n        att_out, _ = self.mha(out, out, out)\n        out = out + att_out\n\n        # Pooling\n        avg_pool = torch.mean(out, dim=1)        \n        max_pool, _ = torch.max(out, dim=1)      \n\n        out = torch.cat([avg_pool, max_pool], dim=1)  \n\n        out = self.dropout(out)\n        return self.fc(out)\n\n\nmodel1 = ScratchBiLSTMAttn(\n    vocab_size=vocab_size,\n    embed_dim=embedding_dim,\n    hidden_dim=hidden_dim,\n    num_labels=len(TARGET_COLS),\n    num_layers=num_layers,\n    dropout=dropout\n)\n\nmodel1.load_state_dict(sd)\nmodel1.to(DEVICE)\nmodel1.eval()\n\n\n\nprint(\"Loaded Model 1 Successfully!\")\n\n\n# ---------------------------------------------\n# INFERENCE LOOP\n# ---------------------------------------------\ntest_ids = torch.tensor(test_df[\"input_ids\"].tolist(), dtype=torch.long)\ntest_loader1 = torch.utils.data.DataLoader(test_ids, batch_size=64, shuffle=False)\n\nall_probs1 = []\nwith torch.no_grad():\n    for batch in tqdm(test_loader1):\n        batch = batch.to(DEVICE)\n        logits = model1(batch)\n        probs = torch.sigmoid(logits).cpu().numpy()\n        all_probs1.extend(probs)\n\nall_probs1 = np.array(all_probs1)\npreds1 = (all_probs1 > thresholds1).astype(int)\n\nsub1 = pd.DataFrame({\"id\": test_df[\"id\"]})\nfor i, col in enumerate(TARGET_COLS):\n    sub1[col] = preds1[:, i]\n\nsub1.to_csv(\"submission_model1_bilstm.csv\", index=False)\n\nprint(\"Model 1 Done → submission_model1_bilstm.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:47:07.644314Z","iopub.execute_input":"2025-12-02T00:47:07.645291Z","iopub.status.idle":"2025-12-02T00:47:09.014289Z","shell.execute_reply.started":"2025-12-02T00:47:07.645257Z","shell.execute_reply":"2025-12-02T00:47:09.013534Z"}},"outputs":[{"name":"stdout","text":"\n=== Loading Model 1 (Scratch BiLSTM) ===\nRecovered architecture:\n vocab_size=5510\n embedding_dim=128\n hidden_dim=384\n num_layers=2\n max_len=80\nLoaded Model 1 Successfully!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 27/27 [00:01<00:00, 23.36it/s]","output_type":"stream"},{"name":"stdout","text":"Model 1 Done → submission_model1_bilstm.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Model 2 - RoBERTa - Large","metadata":{}},{"cell_type":"code","source":"print(\"\\n=== Loading Model 2 (Roberta-Large Fine-Tuned) ===\")\n\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel\n# Pretrained HuggingFace model files (your uploaded folder)\nPRETRAIN_PATH = \"/kaggle/input/pretrain-roberta-abhi/pytorch/default/1/roberta-large\"\n\n# Fine-tuned classifier state dict\nCKPT_PATH = \"/kaggle/input/roberta-large-abhi/pytorch/default/1/best_model.pth\"\n\n\ntokenizer2 = AutoTokenizer.from_pretrained(\n    PRETRAIN_PATH,\n    local_files_only=True\n)\n\n\nclass EmotionClassifier(nn.Module):\n    def __init__(self, pretrained_dir, num_labels=5, dropout_rate=0.3):\n        super().__init__()\n        self.transformer = AutoModel.from_pretrained(\n            pretrained_dir,\n            local_files_only=True\n        )\n        hidden = self.transformer.config.hidden_size   # 1024 for roberta-large\n        self.dropout = nn.Dropout(dropout_rate)\n        self.classifier = nn.Linear(hidden, num_labels)\n\n    def forward(self, ids, mask):\n        out = self.transformer(input_ids=ids, attention_mask=mask)\n        cls = out.last_hidden_state[:, 0]\n        return self.classifier(self.dropout(cls))\n\n\nmodel2 = EmotionClassifier(PRETRAIN_PATH, num_labels=len(TARGET_COLS))\nmodel2.load_state_dict(torch.load(CKPT_PATH, map_location=DEVICE))\nmodel2.to(DEVICE)\nmodel2.eval()\n\nprint(\"Model 2 Loaded Successfully!\")\n\nenc = tokenizer2(\n    test_df[\"clean_text\"].tolist(),\n    truncation=True,\n    padding=True,\n    max_length=256,\n    return_tensors=\"pt\"\n)\n\ntest_loader2 = torch.utils.data.DataLoader(\n    torch.utils.data.TensorDataset(enc[\"input_ids\"], enc[\"attention_mask\"]),\n    batch_size=32,\n    shuffle=False\n)\n\nall_probs2 = []\n\nwith torch.no_grad():\n    for ids, mask in tqdm(test_loader2, desc=\"Running Model 2\"):\n        ids, mask = ids.to(DEVICE), mask.to(DEVICE)\n        logits = model2(ids, mask)\n        probs = torch.sigmoid(logits).cpu().numpy()\n        all_probs2.extend(probs)\n\nall_probs2 = np.array(all_probs2)\npreds2 = (all_probs2 > 0.5).astype(int)\n\n\nsub2 = pd.DataFrame({\"id\": test_df[\"id\"]})\nfor i, col in enumerate(TARGET_COLS):\n    sub2[col] = preds2[:, i]\n\nsub2.to_csv(\"submission.csv\", index=False)\nprint(\"Model 2 Done → submission_model2_transformer.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T01:11:49.880244Z","iopub.execute_input":"2025-12-02T01:11:49.881107Z","iopub.status.idle":"2025-12-02T01:12:52.436671Z","shell.execute_reply.started":"2025-12-02T01:11:49.881072Z","shell.execute_reply":"2025-12-02T01:12:52.435918Z"}},"outputs":[{"name":"stdout","text":"\n=== Loading Model 2 (Roberta-Large Fine-Tuned) ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-12-02 01:11:57.634160: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764637917.870459      38 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764637917.935430      38 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Model 2 Loaded Successfully!\n","output_type":"stream"},{"name":"stderr","text":"Running Model 2: 100%|██████████| 54/54 [00:33<00:00,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"Model 2 Done → submission_model2_transformer.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## MODEL 3 — TF-IDF + LightGBM","metadata":{}},{"cell_type":"code","source":"print(\"\\n=== Loading Model 3 (TF-IDF + LightGBM) ===\")\n\nBASE_DIR = \"/kaggle/input/tfidf-abhi/pytorch/default/1\"\nMODEL3_DIR = f\"{BASE_DIR}/model3_outputs\"\n\nartifact = joblib.load(f\"{MODEL3_DIR}/model3_artifact.pkl\")\n\nword_vec_path = f\"{BASE_DIR}/{artifact['vectorizers']['word'].lstrip('./')}\"\nchar_vec_path = f\"{BASE_DIR}/{artifact['vectorizers']['char'].lstrip('./')}\"\n\ntfidf_word = joblib.load(word_vec_path)\ntfidf_char = joblib.load(char_vec_path)\n\n# Transform text with BOTH vectorizers\nX_test_word = tfidf_word.transform(test_df[\"clean_text\"])\nX_test_char = tfidf_char.transform(test_df[\"clean_text\"])\n\nfrom scipy.sparse import hstack\nX_test = hstack([X_test_word, X_test_char])\n\n# Thresholds\nthresholds3 = np.array(artifact[\"thresholds\"])\n\n\nmodels3 = {}\nfor col in TARGET_COLS:\n    rel = artifact[\"models\"][col].lstrip(\"./\")\n    model_path = f\"{BASE_DIR}/{rel}\"\n    models3[col] = lgb.Booster(model_file=model_path)\n\n\ntest_probs3 = np.zeros((len(test_df), len(TARGET_COLS)))\nfor i, col in enumerate(TARGET_COLS):\n    test_probs3[:, i] = models3[col].predict(X_test)\n\npreds3 = (test_probs3 > thresholds3).astype(int)\n\nsub3 = pd.DataFrame({\"id\": test_df[\"id\"]})\nfor i, col in enumerate(TARGET_COLS):\n    sub3[col] = preds3[:, i]\n\nsub3.to_csv(\"submission_model3_tfidf.csv\", index=False)\nprint(\"Model 3 Done → submission_model3_tfidf.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T01:17:31.316399Z","iopub.execute_input":"2025-12-02T01:17:31.316891Z","iopub.status.idle":"2025-12-02T01:17:32.193967Z","shell.execute_reply.started":"2025-12-02T01:17:31.316866Z","shell.execute_reply":"2025-12-02T01:17:32.193332Z"}},"outputs":[{"name":"stdout","text":"\n=== Loading Model 3 (TF-IDF + LightGBM) ===\nModel 3 Done → submission_model3_tfidf.csv\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### Compare the predictions of all 3 models","metadata":{}},{"cell_type":"code","source":"compare = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n})\n\nfor col in TARGET_COLS:\n    compare[f\"{col}_m1\"] = sub1[col]\n    compare[f\"{col}_m2\"] = sub2[col]\n    compare[f\"{col}_m3\"] = sub3[col]\n\ncompare.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T01:18:07.067320Z","iopub.execute_input":"2025-12-02T01:18:07.067577Z","iopub.status.idle":"2025-12-02T01:18:07.100350Z","shell.execute_reply.started":"2025-12-02T01:18:07.067562Z","shell.execute_reply":"2025-12-02T01:18:07.099522Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"    id  anger_m1  anger_m2  anger_m3  fear_m1  fear_m2  fear_m3  joy_m1  \\\n0    0         1         1         1        1        0        1       0   \n1    1         1         0         0        0        0        0       0   \n2    2         1         1         1        0        1        1       0   \n3    3         0         0         0        1        1        1       0   \n4    4         0         0         0        1        1        1       0   \n5    5         0         0         0        1        0        0       0   \n6    6         0         0         0        1        1        1       0   \n7    7         0         1         0        0        0        1       0   \n8    8         0         0         0        1        1        1       0   \n9    9         0         0         0        1        0        0       0   \n10  10         0         0         0        0        0        1       1   \n11  11         0         0         0        1        1        1       0   \n12  12         0         0         0        1        0        0       0   \n13  13         0         0         0        0        0        0       0   \n14  14         0         0         0        0        0        0       1   \n15  15         0         0         0        0        0        0       1   \n16  16         0         0         0        0        0        0       0   \n17  17         0         0         0        1        1        1       0   \n18  18         1         0         0        0        1        1       0   \n19  19         0         0         0        0        1        1       0   \n\n    joy_m2  joy_m3  sadness_m1  sadness_m2  sadness_m3  surprise_m1  \\\n0        0       1           0           0           0            0   \n1        0       0           0           0           0            1   \n2        0       0           0           0           0            0   \n3        0       0           0           0           0            0   \n4        0       0           0           0           0            1   \n5        1       1           0           0           0            0   \n6        0       0           0           0           0            1   \n7        0       0           1           0           1            0   \n8        0       0           1           1           0            1   \n9        0       0           0           0           0            0   \n10       1       1           0           0           0            0   \n11       0       0           0           1           1            0   \n12       1       0           0           0           0            0   \n13       0       0           0           0           0            0   \n14       1       1           0           0           0            0   \n15       1       1           0           0           0            0   \n16       0       0           0           0           0            1   \n17       0       0           0           0           0            1   \n18       0       0           1           0           0            1   \n19       0       0           0           0           0            0   \n\n    surprise_m2  surprise_m3  \n0             0            1  \n1             0            0  \n2             0            0  \n3             0            0  \n4             1            1  \n5             0            0  \n6             1            1  \n7             0            0  \n8             0            0  \n9             0            0  \n10            0            0  \n11            0            0  \n12            0            0  \n13            0            0  \n14            0            0  \n15            0            0  \n16            0            0  \n17            1            1  \n18            1            0  \n19            0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anger_m1</th>\n      <th>anger_m2</th>\n      <th>anger_m3</th>\n      <th>fear_m1</th>\n      <th>fear_m2</th>\n      <th>fear_m3</th>\n      <th>joy_m1</th>\n      <th>joy_m2</th>\n      <th>joy_m3</th>\n      <th>sadness_m1</th>\n      <th>sadness_m2</th>\n      <th>sadness_m3</th>\n      <th>surprise_m1</th>\n      <th>surprise_m2</th>\n      <th>surprise_m3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}